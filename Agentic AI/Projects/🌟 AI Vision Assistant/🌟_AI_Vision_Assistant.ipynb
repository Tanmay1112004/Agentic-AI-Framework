{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VykNlp8eBo2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# üß† Multi-Model Image Analyzer using OpenRouter + Gradio\n",
        "# Models: GPT-5 Pro | Gemini 2.5 Flash Image | Grok 4 Fast\n",
        "\n",
        "!pip install openai gradio --quiet\n",
        "\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "# üîë Put your OpenRouter API key here\n",
        "OPENROUTER_API_KEY = \"\n",
        "\"\n",
        "\n",
        "# Optional for OpenRouter analytics (not required)\n",
        "SITE_URL = \"https://yourwebsite.com\"\n",
        "SITE_NAME = \"AI Image Analyzer\"\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        ")\n",
        "\n",
        "# ---------- üîç FUNCTION TO ANALYZE IMAGE ----------\n",
        "def analyze_image(image):\n",
        "    \"\"\"\n",
        "    Takes an image (from Gradio) and sends it to GPT-5 Pro, Gemini, and Grok.\n",
        "    Returns text outputs from all models.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return \"Please upload an image.\", \"\", \"\"\n",
        "\n",
        "    # Convert Gradio image object ‚Üí accessible URL or upload\n",
        "    image_path = image\n",
        "    image_url = image_path if image_path.startswith(\"http\") else None\n",
        "\n",
        "    models = {\n",
        "        \"GPT-5 Pro\": \"openai/gpt-5-pro\",\n",
        "        \"Gemini 2.5 Flash\": \"google/gemini-2.5-flash-image\",\n",
        "        \"Grok-4 Fast\": \"x-ai/grok-4-fast\"\n",
        "    }\n",
        "\n",
        "    outputs = {}\n",
        "    for name, model_id in models.items():\n",
        "        try:\n",
        "            completion = client.chat.completions.create(\n",
        "                extra_headers={\n",
        "                    \"HTTP-Referer\": SITE_URL,\n",
        "                    \"X-Title\": SITE_NAME,\n",
        "                },\n",
        "                model=model_id,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"},\n",
        "                            {\n",
        "                                \"type\": \"image_url\",\n",
        "                                \"image_url\": {\n",
        "                                    \"url\": image_url or \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "                                }\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            outputs[name] = completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            outputs[name] = f\"‚ö†Ô∏è Error: {str(e)}\"\n",
        "\n",
        "    return outputs[\"GPT-5 Pro\"], outputs[\"Gemini 2.5 Flash\"], outputs[\"Grok-4 Fast\"]\n",
        "\n",
        "# ---------- üé® GRADIO UI ----------\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"AI Image Analyzer\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        ## üß† AI Image Analyzer Dashboard\n",
        "        Upload an image and get insights from **GPT-5 Pro**, **Gemini 2.5**, and **Grok-4**.\n",
        "        *(Powered by OpenRouter.ai)*\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image(label=\"Upload Image\", type=\"filepath\")\n",
        "\n",
        "    with gr.Row():\n",
        "        gpt5_output = gr.Textbox(label=\"üß© GPT-5 Pro Response\", lines=6)\n",
        "        gemini_output = gr.Textbox(label=\"üåà Gemini 2.5 Flash Response\", lines=6)\n",
        "        grok_output = gr.Textbox(label=\"‚ö° Grok-4 Fast Response\", lines=6)\n",
        "\n",
        "    analyze_btn = gr.Button(\"üîç Analyze Image\")\n",
        "    analyze_btn.click(analyze_image, inputs=image_input, outputs=[gpt5_output, gemini_output, grok_output])\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"‚öôÔ∏è Built by Tanmay | Uses OpenRouter Multi-Model Pipeline\")\n",
        "\n",
        "# ---------- üöÄ LAUNCH ----------\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "XXWRJe3uVmPD",
        "outputId": "985cb107-dc06-40af-da0f-15ee04787cfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e2079943058952be9a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e2079943058952be9a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EOwcoPvgVvF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Multi-Model AI Assistant - Dark Theme\"\"\"\n",
        "\n",
        "!pip install gradio Pillow -q\n",
        "\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "import time\n",
        "\n",
        "# Dark theme CSS\n",
        "custom_css = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
        "\n",
        ".gradio-container {\n",
        "    font-family: 'Inter', sans-serif !important;\n",
        "    background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%) !important;\n",
        "    color: #ffffff !important;\n",
        "}\n",
        "\n",
        ".main-container {\n",
        "    background: rgba(30, 30, 46, 0.95) !important;\n",
        "    backdrop-filter: blur(10px) !important;\n",
        "    border-radius: 20px !important;\n",
        "    padding: 30px !important;\n",
        "    margin: 20px !important;\n",
        "    box-shadow: 0 20px 40px rgba(0,0,0,0.3) !important;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "}\n",
        "\n",
        ".header {\n",
        "    text-align: center;\n",
        "    margin-bottom: 30px;\n",
        "}\n",
        "\n",
        ".header h1 {\n",
        "    background: linear-gradient(135deg, #ff6b6b, #ffd93d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    background-clip: text;\n",
        "    font-weight: 700;\n",
        "    font-size: 2.5em;\n",
        "    margin-bottom: 10px;\n",
        "    text-shadow: 0 0 30px rgba(255, 107, 107, 0.3);\n",
        "}\n",
        "\n",
        ".header p {\n",
        "    color: #b0b0b0;\n",
        "    font-size: 1.1em;\n",
        "}\n",
        "\n",
        ".model-card {\n",
        "    background: linear-gradient(135deg, #2d2d44 0%, #3d3d5c 100%) !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 20px !important;\n",
        "    margin: 15px 0 !important;\n",
        "    border-left: 5px solid #ff6b6b !important;\n",
        "    box-shadow: 0 8px 25px rgba(0,0,0,0.2) !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "}\n",
        "\n",
        ".model-card:hover {\n",
        "    transform: translateY(-3px) !important;\n",
        "    box-shadow: 0 15px 35px rgba(255, 107, 107, 0.2) !important;\n",
        "    border-left-color: #ffd93d !important;\n",
        "}\n",
        "\n",
        ".model-header {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    margin-bottom: 15px;\n",
        "    padding-bottom: 10px;\n",
        "    border-bottom: 2px solid rgba(255, 255, 255, 0.1);\n",
        "}\n",
        "\n",
        ".model-icon {\n",
        "    font-size: 1.5em;\n",
        "    margin-right: 10px;\n",
        "    filter: drop-shadow(0 0 10px rgba(255, 255, 255, 0.3));\n",
        "}\n",
        "\n",
        ".model-name {\n",
        "    font-weight: 600;\n",
        "    color: #ffffff;\n",
        "    font-size: 1.2em;\n",
        "    text-shadow: 0 0 10px rgba(255, 255, 255, 0.2);\n",
        "}\n",
        "\n",
        ".model-response {\n",
        "    color: #e0e0e0;\n",
        "    line-height: 1.6;\n",
        "    background: rgba(40, 40, 60, 0.8);\n",
        "    padding: 15px;\n",
        "    border-radius: 10px;\n",
        "    border-left: 3px solid #ff6b6b;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.05);\n",
        "}\n",
        "\n",
        ".stats {\n",
        "    background: linear-gradient(135deg, #ff6b6b, #ffd93d);\n",
        "    color: #000000;\n",
        "    padding: 8px 15px;\n",
        "    border-radius: 25px;\n",
        "    font-size: 0.85em;\n",
        "    margin-top: 10px;\n",
        "    display: inline-block;\n",
        "    font-weight: 600;\n",
        "    box-shadow: 0 4px 15px rgba(255, 107, 107, 0.3);\n",
        "}\n",
        "\n",
        ".upload-box {\n",
        "    border: 2px dashed #ff6b6b !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 20px !important;\n",
        "    background: rgba(40, 40, 60, 0.8) !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "}\n",
        "\n",
        ".upload-box:hover {\n",
        "    border-color: #ffd93d !important;\n",
        "    box-shadow: 0 0 20px rgba(255, 107, 107, 0.3) !important;\n",
        "}\n",
        "\n",
        ".btn-primary {\n",
        "    background: linear-gradient(135deg, #ff6b6b, #ffd93d) !important;\n",
        "    border: none !important;\n",
        "    border-radius: 25px !important;\n",
        "    padding: 12px 30px !important;\n",
        "    font-weight: 600 !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "    color: #000000 !important;\n",
        "    box-shadow: 0 8px 25px rgba(255, 107, 107, 0.3) !important;\n",
        "}\n",
        "\n",
        ".btn-primary:hover {\n",
        "    transform: translateY(-2px) !important;\n",
        "    box-shadow: 0 12px 30px rgba(255, 107, 107, 0.4) !important;\n",
        "}\n",
        "\n",
        ".model-selector {\n",
        "    background: rgba(40, 40, 60, 0.8) !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 20px !important;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "}\n",
        "\n",
        ".textbox, .textbox input, .textbox textarea {\n",
        "    background: rgba(40, 40, 60, 0.8) !important;\n",
        "    color: #ffffff !important;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "    border-radius: 10px !important;\n",
        "}\n",
        "\n",
        ".textbox label {\n",
        "    color: #ffd93d !important;\n",
        "    font-weight: 600 !important;\n",
        "}\n",
        "\n",
        ".checkbox {\n",
        "    color: #ffffff !important;\n",
        "}\n",
        "\n",
        ".accordion {\n",
        "    background: rgba(40, 40, 60, 0.8) !important;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "    border-radius: 10px !important;\n",
        "}\n",
        "\n",
        ".accordion label {\n",
        "    color: #ffd93d !important;\n",
        "    font-weight: 600 !important;\n",
        "}\n",
        "\n",
        ".footer {\n",
        "    text-align: center;\n",
        "    color: #b0b0b0 !important;\n",
        "    border-top: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "    padding-top: 20px !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def create_model_card(model_name, response, response_time, tokens_used, status):\n",
        "    icon = \"ü§ñ\"\n",
        "    color = \"#ff6b6b\"\n",
        "    if \"GPT\" in model_name:\n",
        "        icon = \"üöÄ\"\n",
        "        color = \"#ff6b6b\"\n",
        "    elif \"Gemini\" in model_name:\n",
        "        icon = \"üîÆ\"\n",
        "        color = \"#4ecdc4\"\n",
        "    elif \"Grok\" in model_name:\n",
        "        icon = \"‚ö°\"\n",
        "        color = \"#ffd93d\"\n",
        "\n",
        "    status_color = \"#4ecdc4\" if status == \"Success\" else \"#ff6b6b\"\n",
        "    status_icon = \"‚úÖ\" if status == \"Success\" else \"‚ùå\"\n",
        "\n",
        "    return f\"\"\"\n",
        "    <div class=\"model-card\" style=\"border-left-color: {color} !important;\">\n",
        "        <div class=\"model-header\">\n",
        "            <span class=\"model-icon\">{icon}</span>\n",
        "            <span class=\"model-name\">{model_name}</span>\n",
        "        </div>\n",
        "        <div class=\"model-response\">\n",
        "            {response}\n",
        "        </div>\n",
        "        <div class=\"stats\">\n",
        "            {status_icon} Status: <span style=\"color: {status_color};\">{status}</span> |\n",
        "            ‚è±Ô∏è {response_time} | ü™ô {tokens_used}\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "def process_single_model(client, model_id, model_name, image, text_prompt):\n",
        "    \"\"\"Process image with a single model using your original code structure\"\"\"\n",
        "    try:\n",
        "        # Convert image using your original method\n",
        "        if hasattr(image, 'save'):\n",
        "            buffered = io.BytesIO()\n",
        "            image.save(buffered, format=\"JPEG\")\n",
        "            image_data = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "        else:\n",
        "            # Handle numpy array from Gradio\n",
        "            pil_image = Image.fromarray(image)\n",
        "            buffered = io.BytesIO()\n",
        "            pil_image.save(buffered, format=\"JPEG\")\n",
        "            image_data = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "        image_url = f\"data:image/jpeg;base64,{image_data}\"\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Your original API call structure\n",
        "        completion = client.chat.completions.create(\n",
        "            extra_headers={\n",
        "                \"HTTP-Referer\": \"https://colab.research.google.com/\",\n",
        "                \"X-Title\": \"AI Vision Assistant\",\n",
        "            },\n",
        "            extra_body={},\n",
        "            model=model_id,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": text_prompt\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": image_url\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        response_time = f\"{time.time() - start_time:.2f}s\"\n",
        "        response = completion.choices[0].message.content\n",
        "        tokens_used = completion.usage.total_tokens if completion.usage else \"N/A\"\n",
        "\n",
        "        return create_model_card(model_name, response, response_time, tokens_used, \"Success\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error: {str(e)}\"\n",
        "        return create_model_card(model_name, error_msg, \"N/A\", \"N/A\", \"Failed\")\n",
        "\n",
        "def process_all_models(api_key, image, text_prompt, use_gpt5, use_gemini, use_grok):\n",
        "    \"\"\"Process image with selected models\"\"\"\n",
        "    if not api_key:\n",
        "        return \"üîë Please enter your OpenRouter API key first!\"\n",
        "\n",
        "    if image is None:\n",
        "        return \"üì∑ Please upload an image first!\"\n",
        "\n",
        "    # Initialize client with your original structure\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        api_key=api_key,\n",
        "    )\n",
        "\n",
        "    models_to_process = []\n",
        "    if use_gpt5:\n",
        "        models_to_process.append((\"openai/gpt-5-pro\", \"GPT-5 Pro\"))\n",
        "    if use_gemini:\n",
        "        models_to_process.append((\"google/gemini-2.5-flash-image\", \"Gemini 2.5 Flash\"))\n",
        "    if use_grok:\n",
        "        models_to_process.append((\"x-ai/grok-4-fast\", \"Grok 4 Fast\"))\n",
        "\n",
        "    if not models_to_process:\n",
        "        return \"ü§ñ Please select at least one model to process!\"\n",
        "\n",
        "    results = []\n",
        "    for model_id, model_name in models_to_process:\n",
        "        result = process_single_model(client, model_id, model_name, image, text_prompt)\n",
        "        results.append(result)\n",
        "\n",
        "    return \"\".join(results)\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(css=custom_css, theme=gr.themes.Default(primary_hue=\"red\")) as demo:\n",
        "    with gr.Column(elem_classes=\"main-container\"):\n",
        "        with gr.Column(elem_classes=\"header\"):\n",
        "            gr.Markdown(\"# üåü AI Vision Assistant\")\n",
        "            gr.Markdown(\"### Compare multiple AI models on image analysis\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # API Key Input\n",
        "                api_key = gr.Textbox(\n",
        "                    label=\"üîë OpenRouter API Key\",\n",
        "                    type=\"password\",\n",
        "                    placeholder=\"Enter your API key here...\",\n",
        "                    info=\"Get your key from https://openrouter.ai\"\n",
        "                )\n",
        "\n",
        "                # Image Upload\n",
        "                image_input = gr.Image(\n",
        "                    label=\"üì∑ Upload Image\",\n",
        "                    type=\"numpy\",\n",
        "                    height=300,\n",
        "                    elem_classes=\"upload-box\"\n",
        "                )\n",
        "\n",
        "                # Prompt Input\n",
        "                text_prompt = gr.Textbox(\n",
        "                    label=\"üí≠ Your Prompt\",\n",
        "                    value=\"What is in this image? Describe it in detail.\",\n",
        "                    lines=3,\n",
        "                    placeholder=\"Ask anything about the image...\"\n",
        "                )\n",
        "\n",
        "                # Model Selection\n",
        "                with gr.Group(elem_classes=\"model-selector\"):\n",
        "                    gr.Markdown(\"### ü§ñ Select Models\")\n",
        "                    use_gpt5 = gr.Checkbox(label=\"GPT-5 Pro\", value=True)\n",
        "                    use_gemini = gr.Checkbox(label=\"Gemini 2.5 Flash\", value=True)\n",
        "                    use_grok = gr.Checkbox(label=\"Grok 4 Fast\", value=True)\n",
        "\n",
        "                # Process Button\n",
        "                process_btn = gr.Button(\n",
        "                    \"üöÄ Analyze Image\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\",\n",
        "                    elem_classes=\"btn-primary\"\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                # Results Output\n",
        "                output_html = gr.HTML(\n",
        "                    label=\"üìä Analysis Results\",\n",
        "                    value=\"<div style='text-align: center; color: #b0b0b0; padding: 40px;'>Your results will appear here after analysis...</div>\"\n",
        "                )\n",
        "\n",
        "    # Examples\n",
        "    with gr.Accordion(\"üí° Example Prompts\", open=False):\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                \"What's in this image? Describe it in detail.\",\n",
        "                \"Analyze the composition and colors in this image.\",\n",
        "                \"What objects can you identify in this image?\",\n",
        "                \"Create a creative story based on this image.\",\n",
        "                \"Describe the mood and atmosphere of this image.\"\n",
        "            ],\n",
        "            inputs=text_prompt,\n",
        "            label=\"Click on any example to use it\"\n",
        "        )\n",
        "\n",
        "    # Footer\n",
        "    gr.Markdown(\"---\", elem_classes=\"footer\")\n",
        "    gr.Markdown(\n",
        "        \"<div style='text-align: center; color: #b0b0b0;'>\"\n",
        "        \"Powered by OpenRouter.ai | GPT-5 Pro ‚Ä¢ Gemini 2.5 Flash ‚Ä¢ Grok 4 Fast\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    # Event handling\n",
        "    process_btn.click(\n",
        "        fn=process_all_models,\n",
        "        inputs=[api_key, image_input, text_prompt, use_gpt5, use_gemini, use_grok],\n",
        "        outputs=output_html\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "print(\"üéØ Launching Dark Theme AI Vision Assistant...\")\n",
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "bYeGF0pYaPWB",
        "outputId": "bb0750c5-cfb8-4a60-fcfd-bb5879f81b80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Launching Dark Theme AI Vision Assistant...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ec65a15c6d1138cb91.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ec65a15c6d1138cb91.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zb-fiu-MaPSv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}